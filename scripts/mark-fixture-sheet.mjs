import 'zx/globals';
import _ from "lodash";
import { LANGS } from "./utils/constants.mjs";
import * as csv from './utils/csv.mjs';
import { loadDictionary } from "./utils/hunspell.mjs";
import razumlivost from '../dist/index.js';
import { core, parse } from "@interslavic/steen-utils";

const flavorizers = razumlivost.flavorizers;

await main();

async function main(targetLang) {
  const rawWords = await csv.parseFile(`__fixtures__/words.csv`);

  const words = rawWords.map((word) => {
    const result = {};
    result.raw = word;
    result.id = word.id;
    result.partOfSpeech = parse.partOfSpeech(word.partOfSpeech);
    result.genesis = word.genesis ? parse.genesis(word.genesis) : undefined;

    const isPhrase = word.partOfSpeech.name === 'phrase';
    for (const lang of ['isv', ...LANGS]) {
      result[lang] = parse.synset(word[lang], { isPhrase })
    }

    return result;
  });

  await fs.mkdirp('__fixtures__/analysis');

  for (const lang of (targetLang ? [targetLang] : LANGS)) {
    console.log(`Analysing language: ${chalk.yellow(lang)}`);

    const analysisPath = `__fixtures__/analysis/${lang}.csv`;
    const records = fs.existsSync(analysisPath)
      ? toPlainMap(await csv.parseFile(analysisPath))
      : {};

    const hunspell = await loadDictionary(lang);
    for (const word of words) {
      const results = flavorizers[lang].compareDebug(word, word.isv, word[lang]);
      const translations = new Set([...word[lang].lemmas()].map(l => l.value));
      const good = results.filter(match => match.distance.percent <= 13).map(match => match.target.context);
      const mediocre = results.filter(match => match.distance.percent > 13 && match.distance.percent < 35).map(match => match.target.context);
      /** @type {string[]} */
      const potentialSearch = flavorizers[lang].flavorize(word.raw.isv, word.partOfSpeech, word.genesis);
      const maybeHelperWords = hunspell && good.length === 0 ? _.sortedUniq(
        potentialSearch
          .filter(w => !translations.has(w) && hunspell.spellSync(w))
          .sort(byLatinAlphabet)
      ) : [];

      const newRecord = {
        id: +word.id,
        isv: word.raw.isv,
        originalTranslation: word.raw[lang],
        translationMatch: new core.Synset({ autogenerated: true }),
        helperWords: new core.Synset({ autogenerated: true }),
        falseFriends: new core.Synset({ autogenerated: true }),
      };

      const matchingGroup = new core.LemmaGroup();
      for (const lemma of [...good, ...mediocre]) {
        matchingGroup.lemmas.push(lemma);
      }

      const helperWordsGroup = new core.LemmaGroup();
      for (const lemma of maybeHelperWords) {
        helperWordsGroup.lemmas.push(new core.Lemma({ value: lemma }));
      }

      if (newRecord.translationMatch.meta.autogenerated) {
        newRecord.translationMatch.meta.autogenerated = good.length === 0 && (mediocre.length + maybeHelperWords.length) > 0;
        newRecord.translationMatch.groups.splice(0, Infinity, matchingGroup);
      }

      if (newRecord.helperWords.meta.autogenerated) {
        newRecord.helperWords.meta.autogenerated = maybeHelperWords.length > 0 || matchingGroup.lemmas.length === 0;
        newRecord.helperWords.groups.splice(0, Infinity, helperWordsGroup);
      }

      if (newRecord.falseFriends.meta.autogenerated) {
        newRecord.falseFriends.meta.autogenerated = matchingGroup.lemmas.length === 0;
      }

      newRecord.translationMatch = newRecord.translationMatch.toString();
      newRecord.helperWords = newRecord.helperWords.toString();
      newRecord.falseFriends = newRecord.falseFriends.toString();

      records[newRecord.id] = newRecord;
    }

    const sorted = _.sortBy(records, r => r.id);
    await csv.writeFile(analysisPath, sorted);
  }
}

function toPlainMap(rows) {
  return rows.reduce((map, row) => {
    map[row.id] = row;
    return map;
  }, {});
}

function byLatinAlphabet(a, b) {
  return a.localeCompare(b, 'sk');
}
